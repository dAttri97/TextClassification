{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('SMSSpamCollection',header=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "0    5572 non-null object\n",
      "1    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n",
      "None\n",
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0:'Type',1:'Message'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column have be renamed for better understanding of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: Type, dtype: int64\n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: Type, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xe89dac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = df['Type']\n",
    "print(classes.value_counts())\n",
    "print(classes.value_counts()/len(classes))\n",
    "(classes.value_counts()/len(classes)).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 86% of the messages are useful and only 14 messages can be considered spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncoding the Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "Name: Type, dtype: object\n",
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "print(classes[:5])\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column type has been LabelEncoded for training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating the Messages for further processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: Message, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['Message']\n",
    "print(text[:10])\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The messages have been randomly written and there is no guarantee of correct spelling and grammer.\n",
    "This can be challenging to process. To overcome such obstacles we must separate the messages with e-mails, phone numbers and urls and other numerical symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common regular expression metacharacters - copied from wikipedia\n",
    "\n",
    "^ Matches the starting position within the string. In line-based tools, it matches the starting position of any line.\n",
    "\n",
    ". Matches any single character (many applications exclude newlines, and exactly which characters are considered newlines is flavor-, character-encoding-, and platform-specific, but it is safe to assume that the line feed character is included). Within POSIX bracket expressions, the dot character matches a literal dot. For example, a.c matches \"abc\", etc., but [a.c] matches only \"a\", \".\", or \"c\".\n",
    "\n",
    "[ ] A bracket expression. Matches a single character that is contained within the brackets. For example, [abc] matches \"a\", \"b\", or \"c\". [a-z] specifies a range which matches any lowercase letter from \"a\" to \"z\". These forms can be mixed: [abcx-z] matches \"a\", \"b\", \"c\", \"x\", \"y\", or \"z\", as does [a-cx-z]. The - character is treated as a literal character if it is the last or the first (after the ^, if present) character within the brackets: [abc-], [-abc]. Note that backslash escapes are not allowed. The ] character can be included in a bracket expression if it is the first (after the ^) character: []abc].\n",
    "\n",
    "[^ ] Matches a single character that is not contained within the brackets. For example, [^abc] matches any character other than \"a\", \"b\", or \"c\". [^a-z] matches any single character that is not a lowercase letter from \"a\" to \"z\". Likewise, literal characters and ranges can be mixed.\n",
    "\n",
    "$ Matches the ending position of the string or the position just before a string-ending newline. In line-based tools, it matches the ending position of any line.\n",
    "\n",
    "( ) Defines a marked subexpression. The string matched within the parentheses can be recalled later (see the next entry, \\n). A marked subexpression is also called a block or capturing group. BRE mode requires ( ).\n",
    "\n",
    "\\n Matches what the nth marked subexpression matched, where n is a digit from 1 to 9. This construct is vaguely defined in the POSIX.2 standard. Some tools allow referencing more than nine capturing groups.\n",
    "\n",
    "* Matches the preceding element zero or more times. For example, abc matches \"ac\", \"abc\", \"abbbc\", etc. [xyz] matches \"\", \"x\", \"y\", \"z\", \"zx\", \"zyx\", \"xyzzy\", and so on. (ab)* matches \"\", \"ab\", \"abab\", \"ababab\", and so on.\n",
    "\n",
    "{m,n} Matches the preceding element at least m and not more than n times. For example, a{3,5} matches only \"aaa\", \"aaaa\", and \"aaaaa\". This is not found in a few older instances of regexes. BRE mode requires {m,n}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    go until jurong point crazy available only in ...\n",
      "1                              ok lar joking wif u oni\n",
      "2    free entry in numbr a wkly comp to win fa cup ...\n",
      "3          u dun say so early hor u c already then say\n",
      "4    nah i don t think he goes to usf he lives arou...\n",
      "Name: Message, dtype: object\n",
      "5567    this is the numbrnd time we have tried numbr c...\n",
      "5568                    will b going to esplanade fr home\n",
      "5569    pity was in mood for that so any other suggest...\n",
      "5570    the guy did some bitching but i acted like i d...\n",
      "5571                            rofl its true to its name\n",
      "Name: Message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Replace email addresses with 'email'\n",
    "processed = text.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                 'emailaddress')\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "    \n",
    "# Replace numbers with 'numbr'\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "\n",
    "# making all the msgs lower_case because Hello,HELLO and hello are all the same\n",
    "processed = processed.str.lower()\n",
    "\n",
    "print(processed.head(5))\n",
    "print(processed.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stop words from the msgs as they don't add any useful info\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x:' '.join(term for term in x.split(' ') if term not in words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    go jurong point crazi avail bugi n great world...\n",
      "1                                ok lar joke wif u oni\n",
      "2    free entri numbr wkli comp win fa cup final tk...\n",
      "3                  u dun say earli hor u c alreadi say\n",
      "4                 nah think goe usf live around though\n",
      "Name: Message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# removing the stem in words\n",
    "stem = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x:' '.join(stem.stem(term) for term in x.split()))\n",
    "\n",
    "print(processed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total Number of unique words : 6562\n",
      "The Most common words in all the unique words: [(u'numbr', 2961), (u'u', 1207), (u'call', 679), (u'go', 456), (u'get', 451), (u'ur', 391), (u'gt', 318), (u'lt', 316), (u'come', 304), (u'ok', 293), (u'free', 284), (u'day', 276), (u'know', 275), (u'love', 266), (u'like', 261)]\n"
     ]
    }
   ],
   "source": [
    "# tokenizing all the msgs for word frequency\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "all_words = []\n",
    "\n",
    "for msg in processed:\n",
    "    words = word_tokenize(msg)\n",
    "    for word in words:\n",
    "        all_words.append(word)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "#printing the neseccary Info\n",
    "print(\"The total Number of unique words : {}\".format(len(all_words)))\n",
    "\n",
    "print(\"The Most common words in all the unique words: {}\".format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we have a very large dataset we are only going to use the 1500 most common words to train our algo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feature = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fucntion to find the common words in a particular msg\n",
    "\n",
    "def find_feat(msg):\n",
    "    words = word_tokenize(msg)\n",
    "    dic = {}\n",
    "    for word in word_feature:\n",
    "        dic[word] = (word in words)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avail\n",
      "buffet\n",
      "world\n",
      "great\n"
     ]
    }
   ],
   "source": [
    "dic = find_feat(processed[0])\n",
    "for key, value in dic.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating hte dictionary for every msg in the data set\n",
    "messages = zip(processed,Y)\n",
    "\n",
    "# defining the reproducable sedd\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages) \n",
    "\n",
    "feature_set = [(find_feat(text),label) for (text,label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 1393)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spiliting the data in train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "training, testing = train_test_split(feature_set,test_size = 0.25, random_state=seed)\n",
    "\n",
    "len(training),len(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the SklearnClassifier in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 94.9748743719\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Necessary Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 93.3237616655\n",
      "Decision Tree Accuracy: 94.1852117732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 94.544149318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 94.615936827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier Accuracy: 95.0466618808\n",
      "Naive Bayes Accuracy: 94.0416367552\n",
      "SVM Linear Accuracy: 94.9748743719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the VotingClassifier for Ensembel Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 94.9748743719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making class label prediction for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_features, labels = zip(*testing)\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing a confusion matrix and a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1213\n",
      "           1       0.91      0.72      0.80       180\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1393\n",
      "   macro avg       0.93      0.85      0.89      1393\n",
      "weighted avg       0.95      0.95      0.95      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1200</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>51</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1200   13\n",
       "       spam        51  129"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
