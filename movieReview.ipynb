{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary Library\n",
    "import random\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the DataSet\n",
    "review = [(list(movie_reviews.words(fileid)),category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Reviews: 2000\n",
      "The Fisrt Review: ([u'plot', u':', u'two', u'teen', u'couples', u'go', u'to', u'a', u'church', u'party', u',', u'drink', u'and', u'then', u'drive', u'.', u'they', u'get', u'into', u'an', u'accident', u'.', u'one', u'of', u'the', u'guys', u'dies', u',', u'but', u'his', u'girlfriend', u'continues', u'to', u'see', u'him', u'in', u'her', u'life', u',', u'and', u'has', u'nightmares', u'.', u'what', u\"'\", u's', u'the', u'deal', u'?', u'watch', u'the', u'movie', u'and', u'\"', u'sorta', u'\"', u'find', u'out', u'.', u'.', u'.', u'critique', u':', u'a', u'mind', u'-', u'fuck', u'movie', u'for', u'the', u'teen', u'generation', u'that', u'touches', u'on', u'a', u'very', u'cool', u'idea', u',', u'but', u'presents', u'it', u'in', u'a', u'very', u'bad', u'package', u'.', u'which', u'is', u'what', u'makes', u'this', u'review', u'an', u'even', u'harder', u'one', u'to', u'write', u',', u'since', u'i', u'generally', u'applaud', u'films', u'which', u'attempt', u'to', u'break', u'the', u'mold', u',', u'mess', u'with', u'your', u'head', u'and', u'such', u'(', u'lost', u'highway', u'&', u'memento', u')', u',', u'but', u'there', u'are', u'good', u'and', u'bad', u'ways', u'of', u'making', u'all', u'types', u'of', u'films', u',', u'and', u'these', u'folks', u'just', u'didn', u\"'\", u't', u'snag', u'this', u'one', u'correctly', u'.', u'they', u'seem', u'to', u'have', u'taken', u'this', u'pretty', u'neat', u'concept', u',', u'but', u'executed', u'it', u'terribly', u'.', u'so', u'what', u'are', u'the', u'problems', u'with', u'the', u'movie', u'?', u'well', u',', u'its', u'main', u'problem', u'is', u'that', u'it', u\"'\", u's', u'simply', u'too', u'jumbled', u'.', u'it', u'starts', u'off', u'\"', u'normal', u'\"', u'but', u'then', u'downshifts', u'into', u'this', u'\"', u'fantasy', u'\"', u'world', u'in', u'which', u'you', u',', u'as', u'an', u'audience', u'member', u',', u'have', u'no', u'idea', u'what', u\"'\", u's', u'going', u'on', u'.', u'there', u'are', u'dreams', u',', u'there', u'are', u'characters', u'coming', u'back', u'from', u'the', u'dead', u',', u'there', u'are', u'others', u'who', u'look', u'like', u'the', u'dead', u',', u'there', u'are', u'strange', u'apparitions', u',', u'there', u'are', u'disappearances', u',', u'there', u'are', u'a', u'looooot', u'of', u'chase', u'scenes', u',', u'there', u'are', u'tons', u'of', u'weird', u'things', u'that', u'happen', u',', u'and', u'most', u'of', u'it', u'is', u'simply', u'not', u'explained', u'.', u'now', u'i', u'personally', u'don', u\"'\", u't', u'mind', u'trying', u'to', u'unravel', u'a', u'film', u'every', u'now', u'and', u'then', u',', u'but', u'when', u'all', u'it', u'does', u'is', u'give', u'me', u'the', u'same', u'clue', u'over', u'and', u'over', u'again', u',', u'i', u'get', u'kind', u'of', u'fed', u'up', u'after', u'a', u'while', u',', u'which', u'is', u'this', u'film', u\"'\", u's', u'biggest', u'problem', u'.', u'it', u\"'\", u's', u'obviously', u'got', u'this', u'big', u'secret', u'to', u'hide', u',', u'but', u'it', u'seems', u'to', u'want', u'to', u'hide', u'it', u'completely', u'until', u'its', u'final', u'five', u'minutes', u'.', u'and', u'do', u'they', u'make', u'things', u'entertaining', u',', u'thrilling', u'or', u'even', u'engaging', u',', u'in', u'the', u'meantime', u'?', u'not', u'really', u'.', u'the', u'sad', u'part', u'is', u'that', u'the', u'arrow', u'and', u'i', u'both', u'dig', u'on', u'flicks', u'like', u'this', u',', u'so', u'we', u'actually', u'figured', u'most', u'of', u'it', u'out', u'by', u'the', u'half', u'-', u'way', u'point', u',', u'so', u'all', u'of', u'the', u'strangeness', u'after', u'that', u'did', u'start', u'to', u'make', u'a', u'little', u'bit', u'of', u'sense', u',', u'but', u'it', u'still', u'didn', u\"'\", u't', u'the', u'make', u'the', u'film', u'all', u'that', u'more', u'entertaining', u'.', u'i', u'guess', u'the', u'bottom', u'line', u'with', u'movies', u'like', u'this', u'is', u'that', u'you', u'should', u'always', u'make', u'sure', u'that', u'the', u'audience', u'is', u'\"', u'into', u'it', u'\"', u'even', u'before', u'they', u'are', u'given', u'the', u'secret', u'password', u'to', u'enter', u'your', u'world', u'of', u'understanding', u'.', u'i', u'mean', u',', u'showing', u'melissa', u'sagemiller', u'running', u'away', u'from', u'visions', u'for', u'about', u'20', u'minutes', u'throughout', u'the', u'movie', u'is', u'just', u'plain', u'lazy', u'!', u'!', u'okay', u',', u'we', u'get', u'it', u'.', u'.', u'.', u'there', u'are', u'people', u'chasing', u'her', u'and', u'we', u'don', u\"'\", u't', u'know', u'who', u'they', u'are', u'.', u'do', u'we', u'really', u'need', u'to', u'see', u'it', u'over', u'and', u'over', u'again', u'?', u'how', u'about', u'giving', u'us', u'different', u'scenes', u'offering', u'further', u'insight', u'into', u'all', u'of', u'the', u'strangeness', u'going', u'down', u'in', u'the', u'movie', u'?', u'apparently', u',', u'the', u'studio', u'took', u'this', u'film', u'away', u'from', u'its', u'director', u'and', u'chopped', u'it', u'up', u'themselves', u',', u'and', u'it', u'shows', u'.', u'there', u'might', u\"'\", u've', u'been', u'a', u'pretty', u'decent', u'teen', u'mind', u'-', u'fuck', u'movie', u'in', u'here', u'somewhere', u',', u'but', u'i', u'guess', u'\"', u'the', u'suits', u'\"', u'decided', u'that', u'turning', u'it', u'into', u'a', u'music', u'video', u'with', u'little', u'edge', u',', u'would', u'make', u'more', u'sense', u'.', u'the', u'actors', u'are', u'pretty', u'good', u'for', u'the', u'most', u'part', u',', u'although', u'wes', u'bentley', u'just', u'seemed', u'to', u'be', u'playing', u'the', u'exact', u'same', u'character', u'that', u'he', u'did', u'in', u'american', u'beauty', u',', u'only', u'in', u'a', u'new', u'neighborhood', u'.', u'but', u'my', u'biggest', u'kudos', u'go', u'out', u'to', u'sagemiller', u',', u'who', u'holds', u'her', u'own', u'throughout', u'the', u'entire', u'film', u',', u'and', u'actually', u'has', u'you', u'feeling', u'her', u'character', u\"'\", u's', u'unraveling', u'.', u'overall', u',', u'the', u'film', u'doesn', u\"'\", u't', u'stick', u'because', u'it', u'doesn', u\"'\", u't', u'entertain', u',', u'it', u\"'\", u's', u'confusing', u',', u'it', u'rarely', u'excites', u'and', u'it', u'feels', u'pretty', u'redundant', u'for', u'most', u'of', u'its', u'runtime', u',', u'despite', u'a', u'pretty', u'cool', u'ending', u'and', u'explanation', u'to', u'all', u'of', u'the', u'craziness', u'that', u'came', u'before', u'it', u'.', u'oh', u',', u'and', u'by', u'the', u'way', u',', u'this', u'is', u'not', u'a', u'horror', u'or', u'teen', u'slasher', u'flick', u'.', u'.', u'.', u'it', u\"'\", u's', u'just', u'packaged', u'to', u'look', u'that', u'way', u'because', u'someone', u'is', u'apparently', u'assuming', u'that', u'the', u'genre', u'is', u'still', u'hot', u'with', u'the', u'kids', u'.', u'it', u'also', u'wrapped', u'production', u'two', u'years', u'ago', u'and', u'has', u'been', u'sitting', u'on', u'the', u'shelves', u'ever', u'since', u'.', u'whatever', u'.', u'.', u'.', u'skip', u'it', u'!', u'where', u\"'\", u's', u'joblo', u'coming', u'from', u'?', u'a', u'nightmare', u'of', u'elm', u'street', u'3', u'(', u'7', u'/', u'10', u')', u'-', u'blair', u'witch', u'2', u'(', u'7', u'/', u'10', u')', u'-', u'the', u'crow', u'(', u'9', u'/', u'10', u')', u'-', u'the', u'crow', u':', u'salvation', u'(', u'4', u'/', u'10', u')', u'-', u'lost', u'highway', u'(', u'10', u'/', u'10', u')', u'-', u'memento', u'(', u'10', u'/', u'10', u')', u'-', u'the', u'others', u'(', u'9', u'/', u'10', u')', u'-', u'stir', u'of', u'echoes', u'(', u'8', u'/', u'10', u')'], u'neg')\n"
     ]
    }
   ],
   "source": [
    "# Viewing the Data\n",
    "rint('Total Number of Reviews: {}'.format(len(review)))\n",
    "print('The Fisrt Review: {}'.format(review[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique Words: 39768\n",
      "Top 15 Most Common Words: [(u',', 77717), (u'the', 76529), (u'.', 65876), (u'a', 38106), (u'and', 35576), (u'of', 34123), (u'to', 31937), (u\"'\", 30585), (u'is', 25195), (u'in', 21822), (u's', 18513), (u'\"', 17612), (u'it', 16107), (u'that', 15924), (u'-', 15595)]\n"
     ]
    }
   ],
   "source": [
    "# Creating a Frequency map for the words in the DataSet\n",
    "all_words=[]\n",
    "for word in movie_reviews.words():\n",
    "    all_words.append(word)\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "print('Total Number of Unique Words: {}'.format(len(all_words)))\n",
    "print('Top 15 Most Common Words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need to build our feature set form the given words. But it will be impractical to use the whole set of 39768 words to build features. So we are going to use the 2500 most common words from the given words to train our model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'sonja', u'askew', u'woods', u'spiders', u'bazooms']\n"
     ]
    }
   ],
   "source": [
    "features = list(all_words.keys())[:2500]\n",
    "print(features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to create feature_set\n",
    "def find_features(doc):\n",
    "    words = set(doc)\n",
    "    dic = {}\n",
    "    for word in words:\n",
    "        dic[word] = (word in features)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = [(find_features(rev),category) for (rev,category) in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spiliting the data in Training and Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training,testing = train_test_split(feature_set,random_state=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training),len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary classifiers\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SklearnClassifier(LogisticRegression())\n",
    "model.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Logistic Regression: 0.69\n"
     ]
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(model,testing)\n",
    "print('Accuracy Score for Logistic Regression: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for K Nearest Neighbour: 0.582\n"
     ]
    }
   ],
   "source": [
    "model = SklearnClassifier(KNeighborsClassifier(n_neighbors=5))\n",
    "model.train(training)\n",
    "accuracy = nltk.classify.accuracy(model,testing)\n",
    "print('Accuracy Score for K Nearest Neighbour: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Decision Tree: 0.592\n"
     ]
    }
   ],
   "source": [
    "model = SklearnClassifier(DecisionTreeClassifier(max_depth=5,max_leaf_nodes=10))\n",
    "model.train(training)\n",
    "accuracy = nltk.classify.accuracy(model,testing)\n",
    "print('Accuracy Score for Decision Tree: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Support Vector Machine: 0.64\n"
     ]
    }
   ],
   "source": [
    "model = SklearnClassifier(SVC(kernel='linear'))\n",
    "model.train(training)\n",
    "accuracy = nltk.classify.accuracy(model,testing)\n",
    "print('Accuracy Score for Support Vector Machine: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above observations we conclude that Logistic Regressor has the best Accuracy**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
